{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-req:** Confirm that you are actually using a GPU instance by running `nvidia-smi` from terminal.  \n",
    "**Important Note:** You will not see GPU being usable unless those modules have been loaded when the session was created.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses tensorboard API to aid with hyperparameter tuning, which can be used in visualization process post the tuning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Env variable to optimize memory usage\n",
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "bffb94db78734e50a7edb02791d265de",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models,preprocessing\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.metrics import f1_score, confusion_matrix,precision_score,recall_score,accuracy_score,log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base path where files will be stored.\n",
    "# This is unpacked from the pickle file created in Step 0.\n",
    "\n",
    "with open('pickledHomeScratchShared.pickle', \"rb\") as f:\n",
    "    baseHomePath,baseScratchPath,baseSharedPath = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set memory growth on GPUs (another step for memory optimization)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "  except RuntimeError as e:\n",
    "    print(\"Error: \"+e)\n",
    "\n",
    "#Print GPU devices, if any, that are available\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Physical GPU Devices: \", physical_devices)\n",
    "\n",
    "logical_devices = tf.config.list_logical_devices('GPU')\n",
    "print(\"Logical GPU Devices: \", logical_devices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose view here by selecting one of the options in `viewChoices` and one of the `colorChoices`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter choice of view by selecting 'choice' variable:\n",
    "viewChoices = ['Transverse','Coronal','Sagittal']\n",
    "choice = viewChoices[2]\n",
    "\n",
    "# File choices\n",
    "fileChoices = {\n",
    "'608' : 'This dataset contains 16-stitiched frames using 235 MRIs from OASIS-1(\"N/A\" CDR rows were filtered) + 373 MRIs from OASIS-2',\n",
    "'809' : 'This dataset contains 16-stitiched frames using 436 MRIs from OASIS-1(\"N/A\" CDR rows assumed as CDR=0) + 373 MRIs from OASIS-2',\n",
    "'508' : 'This dataset contains 16-stitiched frames using 135 MRIs from OASIS-1(Only CDR=0 rows were kept) + 373 MRIs from OASIS-2',\n",
    "'Processed' : 'This dataset contains 436 MRIs from OASIS-1 taken from the \"PROCESSED\" folder. This is NOT stitched.'\n",
    "}\n",
    "fileChoice = list(fileChoices.keys())[3]\n",
    "\n",
    "# Define file names here to make it easier to substitute in next code cell\n",
    "\n",
    "if fileChoice == '608':\n",
    "    transverseFile = 'skip_120_stitched_imgs_t_all_608.pickle'\n",
    "    sagittalFile = 'skip_56_stitched_imgs_s_all_608.pickle'\n",
    "    coronalFile = 'skip_120_stitched_imgs_c_all_608.pickle'\n",
    "    labelsFile = 'all_labels_allImgs_608.pickle'\n",
    "    mriIDFile = 'all_mri_id_allImgs_608.pickle'\n",
    "elif fileChoice == '809':\n",
    "    transverseFile = 'skip_120_stitched_imgs_t_all_809.pickle'\n",
    "    sagittalFile = 'skip_56_stitched_imgs_s_all_809.pickle'\n",
    "    coronalFile = 'skip_120_stitched_imgs_c_all_809.pickle'\n",
    "    labelsFile = 'all_labels_allImgs_809.pickle'\n",
    "    mriIDFile = 'all_mri_id_allImgs_809.pickle'   \n",
    "elif fileChoice == '508':\n",
    "    transverseFile = 'skip_120_stitched_imgs_t.pickle'\n",
    "    sagittalFile = 'skip_56_stitched_imgs_s.pickle'\n",
    "    coronalFile = 'skip_120_stitched_imgs_c.pickle'\n",
    "    labelsFile = 'all_labels.pickle'\n",
    "    mriIDFile = 'all_mri_id.pickle'   \n",
    "elif fileChoice == 'Processed':\n",
    "    transverseFile = 'processed_img_t.pickle'\n",
    "    sagittalFile = 'processed_img_s.pickle'\n",
    "    coronalFile = 'processed_img_c.pickle'\n",
    "    if choice == 'Transverse':\n",
    "        labelsFile = 'all_labels_processed_t.pickle'\n",
    "        mriIDFile = 'all_mri_id_processed_t.pickle'\n",
    "    elif choice == 'Sagittal':\n",
    "        labelsFile = 'all_labels_processed_s.pickle'\n",
    "        mriIDFile = 'all_mri_id_processed_s.pickle'\n",
    "    elif choice == 'Coronal':\n",
    "        labelsFile = 'all_labels_processed_c.pickle'\n",
    "        mriIDFile = 'all_mri_id_processed_c.pickle'     \n",
    "  \n",
    "     \n",
    "\n",
    "print('You have chosen to train with the view of \"{}\"'.format(choice))\n",
    "print(fileChoices[fileChoice])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load objects from serialized files\n",
    "\n",
    "if choice == 'Transverse':\n",
    "    with open(\"{}/{}\".format(baseSharedPath,transverseFile), \"rb\") as f:\n",
    "        img_16frames = pickle.load(f)\n",
    "elif choice == 'Coronal':\n",
    "    with open(\"{}/{}\".format(baseSharedPath,coronalFile), \"rb\") as f:\n",
    "        img_16frames = pickle.load(f)\n",
    "elif choice == 'Sagittal':\n",
    "    with open(\"{}/{}\".format(baseSharedPath,sagittalFile), \"rb\") as f:\n",
    "        img_16frames = pickle.load(f)\n",
    "\n",
    "            \n",
    "with open(\"{}/{}\".format(baseSharedPath,labelsFile), \"rb\") as f:\n",
    "    all_labels = pickle.load(f)\n",
    "    \n",
    "with open(\"{}/{}\".format(baseSharedPath,mriIDFile), \"rb\") as f:\n",
    "    all_mri_id = pickle.load(f)\n",
    "    \n",
    "# 'Stack' the images  since it currently is represented in form of a scalar's shape (508,)\n",
    "# Needs to be more on the lines of (508,x,y)\n",
    "img_16frames = np.stack(img_16frames, axis=0)\n",
    "# Reshape the images to 4 dimensional (1st dim is number of images, 2nd is height, 3rd is width and 4th is scalar)\n",
    "img_16frames = img_16frames.reshape(-1, img_16frames.shape[1], img_16frames.shape[2],1)\n",
    "\n",
    "\n",
    "print('You have chosen to train with the view of \"{}\"'.format(choice))\n",
    "print('Shape of dataset : {}'.format(img_16frames.shape))\n",
    "print('Shape of labels : {}'.format(all_labels.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data using StandardScaler()\n",
    "\n",
    "# Flatten the array along the last dimension\n",
    "img_16frames_flat = img_16frames.reshape(-1, img_16frames.shape[-1])\n",
    "# Standardize the flattened array\n",
    "scaler = StandardScaler()\n",
    "img_16frames_flat_scaled = scaler.fit_transform(img_16frames_flat)\n",
    "# Reshape the standardized array to its original shape and reassign to 'img_16frames'\n",
    "img_16frames = img_16frames_flat_scaled.reshape(img_16frames.shape)\n",
    "\n",
    "print(img_16frames.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to use portion of dataset\n",
    "\"\"\"\n",
    "img_16frames = img_16frames[:235,:,:,:]\n",
    "all_labels = all_labels[:235]\n",
    "\"\"\"\n",
    "\n",
    "print('Shape of split dataset : {}'.format(img_16frames.shape))\n",
    "print('Shape of split labels : {}'.format(all_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "272110bcead64c0bbf70600f6e747bef",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(img_16frames, all_labels\n",
    "                                                     ,test_size=0.2, random_state=13 , stratify=all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ff0083417088409cab6716385d40e67b",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Show a sample image to see if expected view\n",
    "\n",
    "def plot_stitched_img(stitched_img):\n",
    "    # takes arrays from get_mri_array function.\n",
    "    # returns a sample of the image.\n",
    "    plt.close();\n",
    "    plt.figure(figsize=(50,30)) \n",
    "    plt.imshow(stitched_img, cmap=plt.cm.gray_r, interpolation=\"nearest\") \n",
    "    plt.show()\n",
    "\n",
    "plot_stitched_img(img_16frames[0][:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters to tune\n",
    "HP_FILTER_SIZE = hp.HParam('filter_size', hp.Discrete([3, 5, 7]))\n",
    "HP_NUM_FILTERS = hp.HParam('num_filters', hp.Discrete([8, 32, 64]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.2, 0.4))\n",
    "#HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "# Define the metrics to log\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "METRIC_LOSS = 'loss'\n",
    "METRIC_RECALL = 'recall'\n",
    "METRIC_PRECISION = 'precision'\n",
    "METRIC_F1 = 'f1_score'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model function\n",
    "def cnn_model(hparams,fileChoice):\n",
    "    if fileChoice in ['608','809','508']: #Model catering to stitched images\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(hparams[HP_NUM_FILTERS],hparams[HP_FILTER_SIZE], activation='relu',\n",
    "                    input_shape=(img_16frames.shape[1], img_16frames.shape[2], 1)))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(filters=64, kernel_size= 3\n",
    "            ,kernel_regularizer = tf.keras.regularizers.L2(0.01), activation='relu'))\n",
    "        model.add(layers.Dropout(hparams[HP_DROPOUT]))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(filters=128, kernel_size= 3\n",
    "            ,kernel_regularizer = tf.keras.regularizers.L2(0.01), activation='relu'))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(64, activation='relu'))\n",
    "        model.add(layers.Dense(2))\n",
    "        tf.random.set_seed(42)\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "    elif fileChoice == 'Processed': # Model catering to processed images\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(filters=hparams[HP_NUM_FILTERS], kernel_size= hparams[HP_FILTER_SIZE]\n",
    "                        ,kernel_regularizer = tf.keras.regularizers.L2(0.01), activation='relu'\n",
    "                        ,input_shape=(img_16frames.shape[1], img_16frames.shape[2], 1), name = \"C_2d_1\"))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(filters=64, kernel_size= 3\n",
    "                        ,kernel_regularizer = tf.keras.regularizers.L2(0.01), activation='relu', name = \"C_2d_2\"))\n",
    "        model.add(layers.Dropout(hparams[HP_DROPOUT]))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(filters=64, kernel_size= 3\n",
    "                        ,kernel_regularizer = tf.keras.regularizers.L2(0.01), activation='relu', name = \"C_2d_3\"))\n",
    "        model.add(layers.Dropout(0.15))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(filters=64, kernel_size= 3\n",
    "                        ,kernel_regularizer = tf.keras.regularizers.L2(0.01), activation='relu', name = \"C_2d_4\"))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(64, kernel_regularizer = tf.keras.regularizers.L2(0.01), activation='relu', name = \"Dense_1\"))\n",
    "        model.add(layers.Dense(2))\n",
    "        tf.random.set_seed(42)\n",
    "        model.compile(tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define the training function\n",
    "def train_cnn(hparams, log_dir):\n",
    "    model = cnn_model(hparams,fileChoice)\n",
    "    checkpoint_filepath = \"{}/{}\".format(os.path.dirname(baseSharedPath),'tmp') # 'tmp' folder in shared space\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        ,hp.KerasCallback(log_dir, hparams)\n",
    "        ,tf.keras.callbacks.ModelCheckpoint( # Saves best model on each epoch, which can be loaded and used\n",
    "                filepath=checkpoint_filepath, save_weights_only=True,monitor='val_accuracy',mode='max',save_best_only=True)\n",
    "    ]\n",
    "    history = model.fit(X_train,  y_train, epochs=15, \n",
    "                    validation_data=(X_test, y_test), callbacks=callbacks)\n",
    "    model.load_weights(checkpoint_filepath) # Load best model that is available from ModelCheckpoint callback data\n",
    "    # Calculate precision, recall and f1_score as well\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    f1 = f1_score(y_test, y_pred_classes, average='macro')\n",
    "    precision = precision_score(y_test, y_pred_classes, average='macro')\n",
    "    recall = recall_score(y_test, y_pred_classes, average='macro')\n",
    "    accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
    "    loss = log_loss(y_test_binary, y_pred_binary)\n",
    "    return (accuracy,loss,f1,precision,recall)\n",
    "\n",
    "# Define the main function for hyperparameter tuning\n",
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)\n",
    "        accuracy,loss,f1,precision,recall = train_cnn(hparams, run_dir)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "        tf.summary.scalar(METRIC_LOSS, loss, step=1)\n",
    "        tf.summary.scalar(METRIC_F1, f1, step=1)\n",
    "        tf.summary.scalar(METRIC_PRECISION, precision, step=1)\n",
    "        tf.summary.scalar(METRIC_RECALL, recall, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters grid search space\n",
    "runDateTime = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "session_num = 0\n",
    "for filter_size in HP_FILTER_SIZE.domain.values:\n",
    "    for num_filters in HP_NUM_FILTERS.domain.values:\n",
    "        for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "            hparams = {\n",
    "                HP_FILTER_SIZE: filter_size,\n",
    "                HP_NUM_FILTERS: num_filters,\n",
    "                HP_DROPOUT: dropout_rate\n",
    "            }\n",
    "            run_name = f\"run-{session_num}\"\n",
    "            print(f\"--- Starting trial: {run_name}\")\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "            with mirrored_strategy.scope():\n",
    "                argForRun = f\"../data/logs/hparam_tuning/{choice}/{runDateTime}-{fileChoice}/{run_name}\"\n",
    "                run(argForRun,hparams)\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "4a566eafd5bf4566a0bc7e290534994f",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
