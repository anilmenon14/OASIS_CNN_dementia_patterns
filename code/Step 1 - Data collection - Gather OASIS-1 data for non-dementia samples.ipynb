{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "820c71ae",
   "metadata": {},
   "source": [
    "In this notebook, we will gather all the OASIS-1 data , however only filter down to those that explicitly have CDR==0.\n",
    "The code in this notebook will uncompress the tar.gz files and drop the uncompressed folders into scratch folders.\n",
    "It will also clean up any tar.gz files since they are no longer needed once the uncompressed files are available. Additionally, the files of CDR!=0 are also cleaned up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf7295d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard Python distribution libraries\n",
    "import tarfile\n",
    "import os\n",
    "import re\n",
    "import subprocess #To run 'wget' shell command from within Python natively\n",
    "import pickle\n",
    "\n",
    "# Additional libraries \n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d981278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base path where files will be stored.\n",
    "# This is unpacked from the pickle file created in Step 0.\n",
    "\n",
    "with open('pickledHomeScratchShared.pickle', \"rb\") as f:\n",
    "    baseHomePath,baseScratchPath,baseSharedPath = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0894ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download OASIS-1 data labels into a CSV and load into Pandas dataframe \n",
    "subprocess.run([\"wget\", \"-O\", '{}/milestone_II_project/data/oasis_labelled_data/oasis_1_labelled_data.csv'.format(baseHomePath), 'https://www.oasis-brains.org/files/oasis_cross-sectional.csv']);\n",
    "oasis_1_datatable = pd.read_csv('{}/milestone_II_project/data/oasis_labelled_data/oasis_1_labelled_data.csv'.format(baseHomePath))\n",
    "# Display Images which have CDR==0\n",
    "display(oasis_1_datatable[oasis_1_datatable['CDR']==0])\n",
    "# Store list of the IDs\n",
    "cdrZeroList = oasis_1_datatable[oasis_1_datatable['CDR']==0]['ID'].values\n",
    "\n",
    "#Create the tar_gz_files if it does not exist\n",
    "if not os.path.exists(\"{}/data/tar_gz_files\".format(baseScratchPath)):\n",
    "    print('tar_gz_files does not exist.Creating directory...')\n",
    "    subprocess.run([\"mkdir\", \"-p\", \"{}/data/tar_gz_files\".format(baseScratchPath)]) \n",
    "\n",
    "# Create list of tar.gz files to download\n",
    "oasis1_targz_files = ['oasis_cross-sectional_disc{}.tar.gz'.format(i) for i in range(1,13)] # 12 files in total\n",
    "oasis1_targz_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f52b1b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find all tar.gz files in a directory and then uncompress them to another directory.\n",
    "def uncompressTar(datadir):\n",
    "    baseDirs = list()\n",
    "    for root, dirs, files in os.walk(datadir):\n",
    "        for file in files:\n",
    "            if re.match(\"^.+tar\\.gz$\",file):\n",
    "                fullFilePath = root+'/'+ file # Get full file path\n",
    "                tar = tarfile.open(fullFilePath, 'r:gz')\n",
    "                members = tar.getmembers() # Get a list of all the 'members' in the archive\n",
    "                baseDir = os.path.commonprefix([m.name for m in members]) # Get the base directory by finding the common prefix of all members' names\n",
    "                baseDir = baseDir.rstrip(\"/\") # Remove trailing slashes from the base directory\n",
    "                baseDirs.append(baseDir)\n",
    "                uncompressedDirPath = datadir + '/' + baseDir\n",
    "                if os.path.isdir(uncompressedDirPath): # if folder exists, do not try and uncompress and simply warn user\n",
    "                    print(\"The folder {} exists. Hence skipping uncompressing\".format(uncompressedDirPath))\n",
    "                    tar.close()\n",
    "                else:\n",
    "                    print(\"The folder does not exist. Proceeding with uncompressing\")\n",
    "                    tar.extractall(datadir)\n",
    "                    tar.close()   \n",
    "    return baseDirs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322193bd",
   "metadata": {},
   "source": [
    "### Download all the OASIS-1 files and only keep those that are needed (i.e. CDR == 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec5bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to get all the tar.gz files, uncompress them and only keep the ones which are in the labels we need.\n",
    "for tarFile in tqdm(oasis1_targz_files):\n",
    "    # 1. Download tar.gz files (skip unless they already exist) and uncompress them\n",
    "    if not os.path.exists(\"{}/data/tar_gz_files/{}\".format(baseScratchPath,tarFile)):\n",
    "        url = \"https://download.nrg.wustl.edu/data/{}\".format(tarFile);\n",
    "        saveFilePath = \"{}/data/tar_gz_files/{}\".format(baseScratchPath,tarFile);\n",
    "        result = subprocess.run([\"wget\", \"-O\", saveFilePath, url]);\n",
    "    baseDirs = uncompressTar(\"{}/data\".format(baseScratchPath)) # Function returns base directories where uncompressed files will save to\n",
    "    # 2. Code to iterate through base directories where tar files landed and delete those not needed\n",
    "    for baseDir in baseDirs:\n",
    "        folderPath = \"{}/data/{}\".format(baseScratchPath,baseDir)\n",
    "        mriImgFolders = [f for f in os.listdir(folderPath) if not os.path.isfile(os.path.join(folderPath, f))]\n",
    "        for mriImgFolder in mriImgFolders: #Iterate through each mriImgFolder and remove files not needed\n",
    "            if mriImgFolder not in cdrZeroList: #Remove those folders where CDR not equal to zero.\n",
    "                subprocess.run([\"rm\", \"-rf\", folderPath+'/'+mriImgFolder])\n",
    "    # 3. Remove the tar.gz file to clean up space before next file is downloaded\n",
    "    if os.path.exists(\"{}/data/tar_gz_files/{}\".format(baseScratchPath,tarFile)):\n",
    "        subprocess.run([\"rm\", \"-rf\", \"{}/data/tar_gz_files/{}\".format(baseScratchPath,tarFile)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dbf7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
