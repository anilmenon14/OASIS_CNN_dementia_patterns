{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-req:** Confirm that you are actually using a GPU instance by running `nvidia-smi` from terminal.  \n",
    "**Important Note:** You will not see GPU being usable unless those modules have been loaded when the session was created.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Env variable to optimize memory usage\n",
    "import os\n",
    "import datetime\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "bffb94db78734e50a7edb02791d265de",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models,preprocessing,Model\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.metrics import f1_score, confusion_matrix,precision_score,recall_score,accuracy_score,log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from IPython.display import display_html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base path where files will be stored.\n",
    "# This is unpacked from the pickle file created in Step 0.\n",
    "\n",
    "with open('pickledHomeScratchShared.pickle', \"rb\") as f:\n",
    "    baseHomePath,baseScratchPath,baseSharedPath = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set memory growth on GPUs (another step for memory optimization)\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "  except RuntimeError as e:\n",
    "    print(\"Error: \"+e)\n",
    "\n",
    "#Print GPU devices, if any, that are available\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Physical GPU Devices: \", physical_devices)\n",
    "\n",
    "logical_devices = tf.config.list_logical_devices('GPU')\n",
    "print(\"Logical GPU Devices: \", logical_devices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose view here by selecting one of the options in `viewChoices` and one of the `colorChoices`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File choices\n",
    "fileChoices = {\n",
    "'608' : 'This dataset contains 16-stitiched frames using 235 MRIs from OASIS-1(\"N/A\" CDR rows were filtered) + 373 MRIs from OASIS-2',\n",
    "'809' : 'This dataset contains 16-stitiched frames using 436 MRIs from OASIS-1(\"N/A\" CDR rows assumed as CDR=0) + 373 MRIs from OASIS-2',\n",
    "'508' : 'This dataset contains 16-stitiched frames using 135 MRIs from OASIS-1(Only CDR=0 rows were kept) + 373 MRIs from OASIS-2',\n",
    "'Processed' : 'This dataset contains 436 MRIs from OASIS-1 taken from the \"PROCESSED\" folder. This is NOT stitched.',\n",
    "'Pre-trained' : 'Pre-trained InceptionV3 model applied on top of \"Processed\" dataset (i.e. 436 Processed MRIs from OASIS-1)'\n",
    "}\n",
    "# IMPORTANT NOTE: Make choice here, which will be used for rest of notebook.\n",
    "fileChoice = list(fileChoices.keys())[1]\n",
    "print(fileChoice,\" : \",fileChoices[fileChoice])\n",
    "\n",
    "# Choice of view (No need to select since it will loop through all three)\n",
    "viewChoices = ['Transverse','Coronal','Sagittal']\n",
    "\n",
    "# Choose seed value used in remaining part of code\n",
    "seedValueOptions = [14,42,696]\n",
    "seedValue = seedValueOptions[2]\n",
    "print('Seed value used throughout this notebook is {}'.format(seedValue))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to help choose files based on file choice and view choice\n",
    "def chooseFiles(viewChoice,fileChoice):\n",
    "    if fileChoice == '608':\n",
    "        transverseFile = 'skip_120_stitched_imgs_t_all_608.pickle'\n",
    "        sagittalFile = 'skip_56_stitched_imgs_s_all_608.pickle'\n",
    "        coronalFile = 'skip_120_stitched_imgs_c_all_608.pickle'\n",
    "        labelsFile = 'all_labels_allImgs_608.pickle'\n",
    "        mriIDFile = 'all_mri_id_allImgs_608.pickle'\n",
    "    elif fileChoice == '809':\n",
    "        transverseFile = 'skip_120_stitched_imgs_t_all_809.pickle'\n",
    "        sagittalFile = 'skip_56_stitched_imgs_s_all_809.pickle'\n",
    "        coronalFile = 'skip_120_stitched_imgs_c_all_809.pickle'\n",
    "        labelsFile = 'all_labels_allImgs_809.pickle'\n",
    "        mriIDFile = 'all_mri_id_allImgs_809.pickle'   \n",
    "    elif fileChoice == '508':\n",
    "        transverseFile = 'skip_120_stitched_imgs_t.pickle'\n",
    "        sagittalFile = 'skip_56_stitched_imgs_s.pickle'\n",
    "        coronalFile = 'skip_120_stitched_imgs_c.pickle'\n",
    "        labelsFile = 'all_labels.pickle'\n",
    "        mriIDFile = 'all_mri_id.pickle'   \n",
    "    elif fileChoice in ['Processed','Pre-trained']:\n",
    "        transverseFile = 'processed_img_t.pickle'\n",
    "        sagittalFile = 'processed_img_s.pickle'\n",
    "        coronalFile = 'processed_img_c.pickle'\n",
    "        if viewChoice == 'Transverse':\n",
    "            labelsFile = 'all_labels_processed_t.pickle'\n",
    "            mriIDFile = 'all_mri_id_processed_t.pickle'\n",
    "        elif viewChoice == 'Sagittal':\n",
    "            labelsFile = 'all_labels_processed_s.pickle'\n",
    "            mriIDFile = 'all_mri_id_processed_s.pickle'\n",
    "        elif viewChoice == 'Coronal':\n",
    "            labelsFile = 'all_labels_processed_c.pickle'\n",
    "            mriIDFile = 'all_mri_id_processed_c.pickle'  \n",
    "    # Load objects from serialized files\n",
    "    if viewChoice == 'Transverse':\n",
    "        with open(\"{}/{}\".format(baseSharedPath,transverseFile), \"rb\") as f:\n",
    "            img_16frames = pickle.load(f)\n",
    "    elif viewChoice == 'Coronal':\n",
    "        with open(\"{}/{}\".format(baseSharedPath,coronalFile), \"rb\") as f:\n",
    "            img_16frames = pickle.load(f)\n",
    "    elif viewChoice == 'Sagittal':\n",
    "        with open(\"{}/{}\".format(baseSharedPath,sagittalFile), \"rb\") as f:\n",
    "            img_16frames = pickle.load(f)\n",
    "    with open(\"{}/{}\".format(baseSharedPath,labelsFile), \"rb\") as f:\n",
    "        all_labels = pickle.load(f)\n",
    "    with open(\"{}/{}\".format(baseSharedPath,mriIDFile), \"rb\") as f:\n",
    "        all_mri_id = pickle.load(f)\n",
    "        \n",
    "    # 'Stack' the images  since it currently is represented in form of a scalar's shape (x,). Needs to be (x,y,z)\n",
    "    img_16frames = np.stack(img_16frames, axis=0)\n",
    "\n",
    "    if fileChoice == 'Pre-trained': # InceptionV3 needs 3 channels, hence have to adjust\n",
    "        img_16frames = np.repeat(img_16frames[..., np.newaxis], 3, -1)\n",
    "        print('Adjusting image shape for Pre-trained model to {}'.format(img_16frames.shape))\n",
    "    else: # Reshape the images to 4 dimensional (1st dim is number of images, 2nd is height, 3rd is width and 4th is scalar)\n",
    "        img_16frames = img_16frames.reshape(-1, img_16frames.shape[1], img_16frames.shape[2],1)\n",
    "\n",
    "    return(img_16frames,all_labels,all_mri_id)\n",
    "\n",
    "# Code to standardize dataset\n",
    "def standardizeImg(img_16frames):\n",
    "    # Flatten the array along the last dimension\n",
    "    img_16frames_flat = img_16frames.reshape(-1, img_16frames.shape[-1])\n",
    "    # Standardize the flattened array\n",
    "    scaler = StandardScaler()\n",
    "    img_16frames_flat_scaled = scaler.fit_transform(img_16frames_flat)\n",
    "    # Reshape the standardized array to its original shape and reassign to 'img_16frames'\n",
    "    img_16frames = img_16frames_flat_scaled.reshape(img_16frames.shape)\n",
    "    return img_16frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "272110bcead64c0bbf70600f6e747bef",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# No longer needed since this is being done inside the KFold code below.\n",
    "# X_train, X_test, y_train, y_test  = train_test_split(img_16frames, all_labels\n",
    "# ,test_size=0.2, random_state=seedValue , stratify=all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ff0083417088409cab6716385d40e67b",
    "deepnote_cell_type": "code"
   },
   "outputs": [],
   "source": [
    "# Show sample image of one of the images based on the view that was picked\n",
    "\n",
    "def plot_stitched_img(stitched_img):\n",
    "    # takes arrays from get_mri_array function.\n",
    "    # returns a sample of the image.\n",
    "    plt.close();\n",
    "    plt.figure(figsize=(50,30)) \n",
    "    plt.imshow(stitched_img, cmap=plt.cm.gray_r, interpolation=\"nearest\") \n",
    "    plt.show()\n",
    "\n",
    "#plot_stitched_img(img_16frames[0][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose model hyperparameters and define re-usuable code to be able to generate model over each of the cross validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set values of hyperparameters here and substitute in code below.\n",
    "conv2d_1_numfilters = 32\n",
    "conv2d_1_kernelSize = 3\n",
    "dropput_1 = 0.4\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Re-usable code for generating model using hyperparameters in global space\n",
    "def generateModel(fileChoice):\n",
    "    if fileChoice in ['608','809','508']: #Model catering to stitched images\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(filters=conv2d_1_numfilters, kernel_size= conv2d_1_kernelSize, activation='relu',\n",
    "                    input_shape=(img_16frames.shape[1], img_16frames.shape[2], 1)))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(filters=64, kernel_size= 3, kernel_regularizer = tf.keras.regularizers.L2(0.01), activation='relu'))\n",
    "        model.add(layers.Dropout(dropput_1))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(filters=128, kernel_size= 3, kernel_regularizer = tf.keras.regularizers.L2(0.01), activation='relu'))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(64, activation='relu'))\n",
    "        model.add(layers.Dense(2))\n",
    "        tf.random.set_seed(seedValue)\n",
    "        model.compile(tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "    elif fileChoice == 'Processed': # Model catering to processed images\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(filters=conv2d_1_numfilters, kernel_size= conv2d_1_kernelSize\n",
    "                        ,kernel_regularizer = tf.keras.regularizers.L2(0.01), activation='relu'\n",
    "                        ,input_shape=(img_16frames.shape[1], img_16frames.shape[2], 1), name = \"C_2d_1\"))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(filters=64, kernel_size= 3\n",
    "                        ,kernel_regularizer = tf.keras.regularizers.L2(0.01), activation='relu', name = \"C_2d_2\"))\n",
    "        model.add(layers.Dropout(0.15))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(filters=64, kernel_size= 3\n",
    "                        ,kernel_regularizer = tf.keras.regularizers.L2(0.01), activation='relu', name = \"C_2d_3\"))\n",
    "        model.add(layers.Dropout(0.15))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(filters=64, kernel_size= 3\n",
    "                        ,kernel_regularizer = tf.keras.regularizers.L2(0.01), activation='relu', name = \"C_2d_4\"))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(64, kernel_regularizer = tf.keras.regularizers.L2(0.01), activation='relu', name = \"Dense_1\"))\n",
    "        model.add(layers.Dense(2))\n",
    "        tf.random.set_seed(seedValue)\n",
    "        model.compile(tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              #loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              #loss='binary_crossentropy',\n",
    "              #metrics=[tf.keras.metrics.Recall()]\n",
    "              metrics=['accuracy']\n",
    "                     )\n",
    "    \n",
    "    elif fileChoice == 'Pre-trained':\n",
    "        Inceptionv3_model = InceptionV3(input_shape = (img_16frames.shape[1], img_16frames.shape[2], 3)\n",
    "                                , weights = 'imagenet', include_top = False)\n",
    "        Inceptionv3_last_output = Inceptionv3_model.output\n",
    "        Inceptionv3_maxpooled_output = layers.Flatten()(Inceptionv3_last_output)\n",
    "        Inceptionv3_x = layers.Dense(1024, kernel_regularizer = tf.keras.regularizers.L2(0.01),\n",
    "                                     activation = 'relu')(Inceptionv3_maxpooled_output)\n",
    "        Inceptionv3_x = layers.Dropout(0.2)(Inceptionv3_x)\n",
    "        Inceptionv3_x = layers.Dense(8, kernel_regularizer = tf.keras.regularizers.L2(0.01),\n",
    "                                     activation = 'softmax')(Inceptionv3_x)\n",
    "        model = Model(inputs = Inceptionv3_model.input, outputs = Inceptionv3_x)\n",
    "        model.compile(optimizer = tf.keras.optimizers.SGD(lr = 0.0001, momentum = 0.9),\n",
    "                                          loss = 'sparse_categorical_crossentropy',\n",
    "                                          metrics = ['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Reusable code to generate f1_score, precision, recall and confusion matrix for a pair of X_test,y_test against a model\n",
    "def generateF1Score(model,X_test,y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = y_pred.round(1)\n",
    "    y_pred_binary = [0 if x[0] > x[1] else 1 for x in y_pred]\n",
    "    y_test_binary = list(y_test.reshape(1,-1)[0])\n",
    "    f1Score = f1_score(y_test_binary, y_pred_binary, average='macro')\n",
    "    precision = precision_score(y_test_binary, y_pred_binary)\n",
    "    recall = recall_score(y_test_binary, y_pred_binary)\n",
    "    accuracy = accuracy_score(y_test_binary, y_pred_binary)\n",
    "    conf_matx = pd.DataFrame(confusion_matrix(y_test_binary, y_pred_binary), index = ['Actual-Neg', 'Actual-Pos'], columns = ['Pred-Neg', 'Pred-Pos'])\n",
    "    return (f1Score,precision,recall,accuracy,conf_matx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If 'Pre-trained', have to change img_16frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main code cell for training over stratified k-fold data\n",
    "\n",
    "allModelsScores = dict() # Initialize a dictionary that stores all the information of all the models\n",
    "n_splits = 5\n",
    "\n",
    "for viewChoice in viewChoices:\n",
    "    print('The choice of view is {}'.format(viewChoice))\n",
    "    img_16frames,all_labels,all_mri_id = chooseFiles(viewChoice,fileChoice) # Generate dataset\n",
    "    img_16frames = standardizeImg(img_16frames) # Standardize dataset\n",
    "    modelCVScores = [] # Empty list to store scores from each iteration\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seedValue) # Define the Stratified KFold object\n",
    "    # Train for chosen view over k-folds using distributed strategy\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    with mirrored_strategy.scope():\n",
    "        # Iterate through each fold\n",
    "        for i, (train_index, test_index) in enumerate(skf.split(img_16frames,all_labels)):\n",
    "            print('Iteration: {} for {}'.format(i+1,viewChoice))\n",
    "            # Generate model from scratch \n",
    "            model = generateModel(fileChoice)\n",
    "            checkpoint_filepath = \"{}/{}\".format(os.path.dirname(baseSharedPath),'tmp') # 'tmp' folder in shared space\n",
    "            callbacks = [\n",
    "                tf.keras.callbacks.ModelCheckpoint( # Saves best model on each epoch, which can be loaded and used\n",
    "                    filepath=checkpoint_filepath, save_weights_only=True,monitor='val_accuracy',mode='max',save_best_only=True)\n",
    "            ]\n",
    "            # Generate new datasets for X_train, X_test, y_train, y_test on each run\n",
    "            X_train, X_test =  img_16frames[train_index],img_16frames[test_index]\n",
    "            y_train, y_test = all_labels[train_index],all_labels[test_index]\n",
    "            ActualNegativesInTrain ,ActualPositivesInTrain = len(y_train[y_train==0]),len(y_train[y_train==1])\n",
    "            ActualNegativesInTest, ActualPositivesInTest= len(y_test[y_test==0]),len(y_test[y_test==1])\n",
    "            model.fit(X_train,  y_train, epochs=20, \n",
    "                            validation_data=(X_test, y_test),callbacks=callbacks,verbose=2)\n",
    "            history = model.load_weights(checkpoint_filepath) # Load best model that is available from ModelCheckpoint callback data\n",
    "            # Store the evaluation metrics for this fold\n",
    "            modelCVScores.append([ActualNegativesInTrain ,ActualPositivesInTrain\n",
    "                                  ,ActualNegativesInTest, ActualPositivesInTest\n",
    "                                  ,*generateF1Score(model,X_test,y_test)])\n",
    "        allModelsScores[viewChoice] = modelCVScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all of the confusion matrices one over the other\n",
    "\n",
    "conf_mat_list = [[allModelsScores[key][i][-1] for key in allModelsScores] for i in range(n_splits)]\n",
    "i = 0\n",
    "for iteration in conf_mat_list:\n",
    "    i += 1\n",
    "    confT,confC,confS = iteration\n",
    "    confT_styler = confT.style.set_table_attributes(\"style='display:inline'\").set_caption('Iteration {}-{}'.format(i,'Transvere'))\n",
    "    confC_styler = confC.style.set_table_attributes(\"style='display:inline'\").set_caption('Iteration {}-{}'.format(i,'Coronal'))\n",
    "    confS_styler = confS.style.set_table_attributes(\"style='display:inline'\").set_caption('Iteration {}-{}'.format(i,'Sagittal'))\n",
    "    space = \"\\xa0\" * 10\n",
    "    display_html(confT_styler._repr_html_()+space+confC_styler._repr_html_()+space+confS_styler._repr_html_()\n",
    "             , raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack all of the models from allModelsScores and display\n",
    "print('Below are results for a {} K-Fold validation training using the {} dataset'.format(n_splits,fileChoice))\n",
    "modelDfT,modelDfC,modelDfS = [pd.DataFrame([item[0:-1] for item in allModelsScores[key]]\n",
    "             ,columns= [\"ActualNegativesInTrain\" ,\"ActualPositivesInTrain\"\n",
    "                              ,\"ActualNegativesInTest\", \"ActualPositivesInTest\"\n",
    "                        ,\"f1Score\",\"precision\",\"recall\",\"accuracy\"]) for key in allModelsScores]\n",
    "\n",
    "modelDfT_styler = modelDfT.style.set_table_attributes(\"style='display:inline'\").set_caption('Transvere')\n",
    "modelDfC_styler = modelDfC.style.set_table_attributes(\"style='display:inline'\").set_caption('Coronal')\n",
    "modelDfS_styler = modelDfS.style.set_table_attributes(\"style='display:inline'\").set_caption('Sagittal')\n",
    "\n",
    "space = \"\\xa0\" * 10\n",
    "display_html(modelDfT_styler._repr_html_()+space+modelDfC_styler._repr_html_()+space+modelDfS_styler._repr_html_()\n",
    "             , raw=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print average across all the models\n",
    "pd.DataFrame([modelDfT.mean(),modelDfC.mean(),modelDfS.mean()],index=viewChoices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle results with appropriate name so that it can be loaded and used if needed\n",
    "runDateTime = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "with open(\"{}/all_model_scores_{}_{}fold_seed{}_{}.pickle\".format(baseSharedPath+'/model_scores',fileChoice,n_splits,seedValue,runDateTime), \"wb\") as f:\n",
    "    pickle.dump(allModelsScores, f)"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "4a566eafd5bf4566a0bc7e290534994f",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
