{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries included in Python distribution\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# Installed libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import nibabel as nib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Navigate through all images in directory iteratively and display in pandas dataframe the dimensions of the images\n",
    "\n",
    "**Methodology** :\n",
    "1. Use *Nibabel* package to convert the Nifti1 to numpy.\n",
    "2. Obtain full path to file and then the shape of the image.\n",
    "\n",
    "**Objectives** : \n",
    "1. Find out if all the images are of the same dimension.\n",
    "2. Store information of all image files to be able to traverse easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base path where files will be stored.\n",
    "# This is unpacked from the pickle file created in Step 0.\n",
    "\n",
    "with open('pickledHomeScratchShared.pickle', \"rb\") as f:\n",
    "    baseHomePath,baseScratchPath,baseSharedPath = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Traverse through the whole directory and build all paths if 'nifti.img' or 'anon.img' files are found\n",
    "\n",
    "fileShapeList = list()\n",
    "for root, dirs, files in os.walk(\"{}/data\".format(baseScratchPath)):\n",
    "    for file in files:\n",
    "        if re.match(\"^.+nifti\\.img$|^.+anon\\.img$\",file):\n",
    "            fullFilePath = root+'/'+file\n",
    "            # Step 2: Convert the image to Numpy ndarray object using Nibael and find the shape of the object\n",
    "            img = nib.load(fullFilePath) # Note: This is a lazy load and does not load image into memory yet\n",
    "            mriImgID = re.search(r'/([^/]+)$', os.path.dirname(os.path.dirname(fullFilePath))).group(1)\n",
    "            fileShapeList.append((mriImgID,file,fullFilePath,img.shape)) #Delete later\n",
    "\n",
    "# Step 3: Display in form of pandas dataframe that contains all sessions from each MRI visit for all patients\n",
    "imageInfoDf_AllSessions = pd.DataFrame(fileShapeList,columns=['MRI_ID','File name','Full path','Shape of image'])\n",
    "imageInfoDf_AllSessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total unique MRI IDs seen in list\n",
    "print(\"Total unique MRI_ID seen in the DataFrame is : {}\".format(len(set(imageInfoDf_AllSessions['MRI_ID'].values))))\n",
    "# Checking if each of the images in our dataset has the exact same shape. If not, we will need to process them further.\n",
    "print('Confirming the unique list of shapes of MRI files in the dataset: ',end=\"\")\n",
    "print(set(imageInfoDf_AllSessions['Shape of image'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both OASIS-1 and OASIS-2, the practitioners have takes 3-4 sessions of MRIs for each visit. In total we have 508 visits, however have 1894 sessions in total due to multiple sessions taken per visit.  \n",
    "Since it is computationally expensive to work with all of the 1894 sessions, we will randomly choose **only 1 MRI per visit** using code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only 1 session from each of the MRI (each MRI has 3 sessions)\n",
    "# 809 rows in total\n",
    "\n",
    "imageInfoDf = imageInfoDf_AllSessions.groupby('MRI_ID').apply(pd.DataFrame.sample, n=1).reset_index(drop=True)\n",
    "imageInfoDf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2 : Load image using Nibabel and display cross sections of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a random file from imageInfoDf and load using Nibabel\n",
    "randImgIndex = random.randint(0,len(imageInfoDf)-1)\n",
    "sampleImg = nib.load(imageInfoDf.iloc[randImgIndex]['Full path'])\n",
    "print('Sample picked out is : {}'.format(imageInfoDf.iloc[randImgIndex]['Full path']))\n",
    "# Get Numpy data of image\n",
    "sampleImgData = sampleImg.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review shape of the Numpy ndarray that encodes the image data\n",
    "sampleImgData.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object above has 4 dimensions. The first three dimensions are those of the dimensions of the *'volume'* of the MRI (i.e. height, width and depth) and the 4th dimension is *time* as there are sometimes samples collected over different epochs while in the same MRI session. In our case, there is only one time recording in each session (i.e. 4th dimension is '1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions \n",
    "\n",
    "# Function to show image using Numpy ndarray\n",
    "def showImg(ndarr):\n",
    "    return plt.imshow(ndarr, cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "\n",
    "# Function that can retrieve number of frames for animation to use as well as initial imshow object\n",
    "def retrieveFrames(planeOfViewing,sample):\n",
    "    if planeOfViewing == \"Sagittal\":\n",
    "        return sample.shape[2]\n",
    "    elif planeOfViewing == \"Transverse\":\n",
    "        return sample.shape[1]\n",
    "    elif planeOfViewing == \"Coronal\":\n",
    "        return sample.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static image showing data\n",
    "plt.close();\n",
    "\n",
    "# Code to display image\n",
    "showImg(sampleImgData[:,128,:,0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planes of MRI \n",
    "<img src=\"../data/static/mri_planes_gnu.jpg\" width=\"300\" height=\"800\">\n",
    "\n",
    "Using the dimensions of the 4-D Matrix data, we can traverse through each of the planes of the planes (i.e. 1st three dimensions since 4th dimension of time has only one value).   \n",
    "Below is an attempt to view the images through an interactive animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose plane along which to view the cross sections of images\n",
    "planeOptions = [\"Sagittal\",\"Coronal\",\"Transverse\"]\n",
    "planeOfViewing = planeOptions[2]\n",
    "print('Plane chosen = {}'.format(planeOfViewing))\n",
    "\n",
    "# Retrieve the number of frames to iterate over\n",
    "framesAvailable = retrieveFrames(planeOfViewing,sampleImgData)\n",
    "print(framesAvailable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Retrieve the number of frames to iterate over\n",
    "framesAvailable = retrieveFrames(planeOfViewing,sampleImgData)\n",
    "\n",
    "plt.ion() #Interactive mode set to ON\n",
    "plt.close(); # Close any existing open plot\n",
    "\n",
    "# Randomly initialize IM object\n",
    "if planeOfViewing == \"Sagittal\":\n",
    "    im = plt.imshow(sampleImgData[:,:,0,0], cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "elif planeOfViewing == \"Transverse\":\n",
    "    im = plt.imshow(sampleImgData[:,0,:,0], cmap=plt.cm.gray_r, interpolation=\"nearest\")\n",
    "elif planeOfViewing == \"Coronal\":\n",
    "    im = plt.imshow(sampleImgData[100,:,:,0], cmap=plt.cm.gray_r, interpolation=\"nearest\") \n",
    "\n",
    "def animate(frame):\n",
    "    if planeOfViewing == \"Sagittal\":\n",
    "        im.set_array(sampleImgData[:,:,frame,0]) \n",
    "    elif planeOfViewing == \"Transverse\":\n",
    "        im.set_array(sampleImgData[:,frame,:,0]) \n",
    "    elif planeOfViewing == \"Coronal\":\n",
    "        im.set_array(sampleImgData[frame,:,:,0]) \n",
    "    return im;\n",
    "\n",
    "\n",
    "# Uncomment to see animation\n",
    "\"\"\"\n",
    "anim= FuncAnimation(plt.gcf(), animate, frames=framesAvailable, interval=10, blit=False, repeat=False);\n",
    "\n",
    "plt.show();\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3 : Stitch all images of a single MRI onto a 2-D plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to choose frame used by stitch_image\n",
    "def img_frame(mri_arr,frame,planeOfViewing,switchColor=False):\n",
    "    if planeOfViewing == \"Sagittal\":\n",
    "        returnImg = mri_arr[:,:,frame,0] \n",
    "    elif planeOfViewing == \"Transverse\":\n",
    "        returnImg = mri_arr[:,frame,:,0]\n",
    "    elif planeOfViewing == \"Coronal\":\n",
    "        returnImg =  mri_arr[frame,:,:,0]\n",
    "    if switchColor==True:\n",
    "        maxVal = returnImg.max()\n",
    "        returnImg = maxVal - returnImg\n",
    "    return returnImg\n",
    "\n",
    "\n",
    "# Function to stitch_image\n",
    "def stitch_image_allimgs(mri_arr,planeOfViewing):\n",
    "    # takes arrays from get_mri_array function.\n",
    "    # returns a stitched array.\n",
    "\n",
    "    n_frames = retrieveFrames(planeOfViewing,mri_arr) # Number of frames in the MRI\n",
    "    n_rows = 16 \n",
    "    n_cols = int(n_frames/n_rows)\n",
    "    frame_dim = (256,256) if n_frames == 128 else (256,128) # Shape of each frame\n",
    "    stitch_dim = (n_rows,) # rows,cols\n",
    "    \n",
    "    complete_stitched_img = np.empty((0, frame_dim[1]*n_rows))\n",
    "    stitched_img_row = np.empty((frame_dim[0],0))\n",
    "    x = 0\n",
    "    for frame in range(n_frames):\n",
    "        stitched_img_row = np.hstack((stitched_img_row, img_frame(mri_arr,frame,planeOfViewing)))\n",
    "        x += 1\n",
    "        if x == n_rows:\n",
    "            complete_stitched_img = np.vstack((complete_stitched_img, stitched_img_row))\n",
    "            stitched_img_row = np.empty((frame_dim[0],0))\n",
    "            x = 0\n",
    "    return complete_stitched_img\n",
    "\n",
    "# Function to stitch_image after skipping frames from start and end as specified\n",
    "def stitch_image_skipframes(mri_arr,planeOfViewing,skipFrames=0,switchColor=False):\n",
    "    # takes arrays from get_mri_array function.\n",
    "    # returns a stitched array.\n",
    "\n",
    "    n_frames = retrieveFrames(planeOfViewing,mri_arr) # Number of frames in the MRI\n",
    "    n_rows = 16 \n",
    "    n_cols = int(n_frames/n_rows)\n",
    "    frame_dim = (256,256) if n_frames == 128 else (256,128) # Shape of each frame\n",
    "    stitch_dim = (n_rows,) # rows,cols\n",
    "    \n",
    "    complete_stitched_img = np.empty((0, frame_dim[1]*n_rows))\n",
    "    stitched_img_row = np.empty((frame_dim[0],0))\n",
    "    x = 0\n",
    "    for frame in range(skipFrames,n_frames-skipFrames):\n",
    "        stitched_img_row = np.hstack((stitched_img_row, img_frame(mri_arr,frame,planeOfViewing,switchColor)))\n",
    "        x += 1\n",
    "        if x == n_rows:\n",
    "            complete_stitched_img = np.vstack((complete_stitched_img, stitched_img_row))\n",
    "            stitched_img_row = np.empty((frame_dim[0],0))\n",
    "            x = 0\n",
    "    return complete_stitched_img\n",
    "\n",
    "# Function for displaying stitched images\n",
    "def plot_stitched_img(stitched_img):\n",
    "    # takes arrays from get_mri_array function.\n",
    "    # returns a sample of the image.\n",
    "    plt.close();\n",
    "    plt.figure(figsize=(50,30)) \n",
    "    plt.imshow(stitched_img, cmap=plt.cm.gray_r, interpolation=\"nearest\") \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4 : Pull in CDR labels, transform to binary and then join to `ImageInfoDf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in files containing labels\n",
    "oasis_1_datatable = pd.read_csv('{}/milestone_II_project/data/oasis_labelled_data/oasis_1_labelled_data.csv'.format(baseHomePath))\n",
    "oasis_2_datatable = pd.read_excel('{}/milestone_II_project/data/oasis_labelled_data/oasis_2_labelled_data.xlsx'.format(baseHomePath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize content from both datatables and make it into a single style\n",
    "\n",
    "# Filter and transform to datasets that will be used in the project\n",
    "\n",
    "oasis1DataSet = oasis_1_datatable.copy() # 436 rows expected from this operation\n",
    "oasis1DataSet['CDR'] = oasis1DataSet.CDR.fillna(0) # Big assumption that 'NA' == not demented\n",
    "oasis1DataSet['dem_labels'] = oasis1DataSet['CDR'].map(lambda x: 0 if x==0 else 1)\n",
    "oasis1DataSet.rename(columns={'ID':'MRI_ID'},inplace=True)\n",
    "oasis1DataSet = oasis1DataSet[['MRI_ID','dem_labels']]\n",
    "\n",
    "oasis2DataSet = oasis_2_datatable.copy() # 373 rows will be seen in this DataFrame\n",
    "oasis2DataSet['dem_labels'] = oasis2DataSet['CDR'].map(lambda x: 0 if x==0 else 1)\n",
    "oasis2DataSet.rename(columns={'MRI ID':'MRI_ID'},inplace=True)\n",
    "oasis2DataSet = oasis2DataSet[['MRI_ID','dem_labels']]\n",
    "\n",
    "# Concatenate the data from the OASIS-1 and OASIS-2 labels to 436+373 = \n",
    "oasis_1_2_dataset = pd.concat([oasis1DataSet, oasis2DataSet], axis=0)\n",
    "\n",
    "\n",
    "# Link imageInfoDf dataframe (i.e. containing image metadata) to oasis_1_2_dataset(i.e. containing labels) \n",
    "# to create `oasisMasterDf`\n",
    "\n",
    "oasisMasterDf = imageInfoDf.merge(right =oasis_1_2_dataset,on='MRI_ID')\n",
    "display(oasisMasterDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5 : Create arrays and serialize to files using pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 - Create numpy `ndarray` of all the labels in the same order as it is in `oasisMasterDf`\n",
    "\n",
    "#### Also, optionally creating a list of the `MRI_ID`, in case this is necessary for any downstream tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_allImgs_809 = oasisMasterDf['dem_labels'].to_numpy()\n",
    "all_mri_id_allImgs_809 = oasisMasterDf['MRI_ID'].to_numpy()\n",
    "\n",
    "print(all_labels_allImgs_809.shape)\n",
    "print(all_mri_id_allImgs_809.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 - Serialize and store each of `all_labels` and `all_mri_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"{}/all_labels_allImgs_809.pickle\".format(baseSharedPath), \"wb\") as f:\n",
    "    pickle.dump(all_labels_allImgs_809, f)\n",
    "    \n",
    "with open(\"{}/all_mri_id_allImgs_809.pickle\".format(baseSharedPath), \"wb\") as f:\n",
    "    pickle.dump(all_mri_id_allImgs_809, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 6 : Create stitiched `Transverse` arrays using `skipFrames=120` on each end to reduce dimensionality to `256 -120 -120 = 16` frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 - Create numpy `ndarray` of all the images in the same order as it is in `oasisMasterDf`.\n",
    "#### Here, we are keeping only the middle 16 slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Convert image path to numpy ndarray as this is the one we will be using.\n",
    "ImgPathAsNumpy = oasisMasterDf['Full path'].to_numpy()\n",
    "\n",
    "# Vectorize step 1: Convert the function nib.load to a vectorized function and apply\n",
    "vec_func_nib = np.vectorize(nib.load)\n",
    "file_nib_to_np = vec_func_nib(ImgPathAsNumpy)\n",
    "# Vectorize step 2: Convert the function .get_fdata() class function of the file_nib_to_np objects to a vectorized function and apply\n",
    "vec_func_mri = np.vectorize(nib.spm2analyze.Spm2AnalyzeImage.get_fdata,otypes=[np.ndarray])\n",
    "mri_data = vec_func_mri(file_nib_to_np)\n",
    "# Vectorize step 3: Convert the function stitch_image_allimgs to a vectorized function and apply\n",
    "vec_func_stitch = np.vectorize(stitch_image_skipframes,otypes=[np.ndarray])\n",
    "skip_120_stitched_imgs_t_all = vec_func_stitch(mri_data,planeOfViewing = 'Transverse',skipFrames=120)\n",
    "skip_56_stitched_imgs_s_all = vec_func_stitch(mri_data,planeOfViewing = 'Sagittal',skipFrames=56)\n",
    "skip_120_stitched_imgs_c_all = vec_func_stitch(mri_data,planeOfViewing = 'Coronal',skipFrames=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"{}/skip_120_stitched_imgs_t_all_809.pickle\".format(baseSharedPath), \"wb\") as f:\n",
    "    pickle.dump(skip_120_stitched_imgs_t_all, f)\n",
    "with open(\"{}/skip_56_stitched_imgs_s_all_809.pickle\".format(baseSharedPath), \"wb\") as f:\n",
    "    pickle.dump(skip_56_stitched_imgs_s_all, f)\n",
    "with open(\"{}/skip_120_stitched_imgs_c_all_809.pickle\".format(baseSharedPath), \"wb\") as f:\n",
    "    pickle.dump(skip_120_stitched_imgs_c_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(skip_120_stitched_imgs_t_all.shape)\n",
    "print(skip_56_stitched_imgs_s_all.shape)\n",
    "print(skip_120_stitched_imgs_c_all.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
