{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3a4d5a0",
   "metadata": {},
   "source": [
    "In this notebook, we will gather all the OASIS-2 data .\n",
    "The code in this notebook will uncompress the tar.gz files and drop the uncompressed folders into scratch folders.\n",
    "It will also clean up any tar.gz files since they are no longer needed once the uncompressed files are available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5faebdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard Python distribution libraries\n",
    "import tarfile\n",
    "import os\n",
    "import re\n",
    "import subprocess\n",
    "import pickle\n",
    "\n",
    "# Additional libraries \n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e60e6b9",
   "metadata": {},
   "source": [
    "### Download each of the OASIS-2 tar.gz files \n",
    "This is data provided directly from the OASIS-2 website as part of instructions stated in [this link](https://www.oasis-brains.org/#data). Once there, navigate to 'OASIS-2' and the 'Downlaod instructions' references the links being used below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2b083cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base path where files will be stored.\n",
    "# This is unpacked from the pickle file created in Step 0.\n",
    "\n",
    "with open('pickledHomeScratchShared.pickle', \"rb\") as f:\n",
    "    baseHomePath,baseScratchPath,baseSharedPath = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c96c31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the tar_gz_files if it does not exist\n",
    "if not os.path.exists(\"{}/data/tar_gz_files\".format(baseScratchPath)):\n",
    "    print('tar_gz_files does not exist.Creating directory...')\n",
    "    subprocess.run([\"mkdir\", \"-p\", \"{}/data/tar_gz_files\".format(baseScratchPath)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b3485d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find all tar.gz files in a directory and then uncompress them to another directory.\n",
    "\"\"\"\n",
    "# Old code below just for reference before testing new code\n",
    "def uncompressTar(datadir):\n",
    "    for root, dirs, files in os.walk(datadir):\n",
    "        for file in files:\n",
    "            if re.match(\"^.+tar\\.gz$\",file):\n",
    "                fullFilePath = root+'/'+ file # Get full file path\n",
    "                uncompressedDirPath = re.sub(\"\\.tar\\.gz$\", \"\", datadir + '/' + file)\n",
    "                if os.path.isdir(uncompressedDirPath): # if file exists, do not try and uncompress and simply warn user\n",
    "                    print(\"The folder {} exists. Hence skipping uncompressing\".format(uncompressedDirPath))\n",
    "                else:\n",
    "                    print(\"The folder does not exist. Proceeding with uncompressing\")\n",
    "                    tar = tarfile.open(fullFilePath, 'r:gz')\n",
    "                    tar.extractall(datadir)\n",
    "                    tar.close()          \n",
    "                    \n",
    "# Run function to uncompress tar.gz files\n",
    "uncompressTar(\"/home/anilcm/milestone_II_project/data\")\n",
    "\"\"\"\n",
    "\n",
    "# Function to find all tar.gz files in a directory and then uncompress them to another directory.\n",
    "def uncompressTar(datadir):\n",
    "    baseDirs = list()\n",
    "    for root, dirs, files in os.walk(datadir):\n",
    "        for file in files:\n",
    "            if re.match(\"^.+tar\\.gz$\",file):\n",
    "                fullFilePath = root+'/'+ file # Get full file path\n",
    "                tar = tarfile.open(fullFilePath, 'r:gz')\n",
    "                members = tar.getmembers() # Get a list of all the 'members' in the archive\n",
    "                baseDir = os.path.commonprefix([m.name for m in members]) # Get the base directory by finding the common prefix of all members' names\n",
    "                baseDir = baseDir.rstrip(\"/\") # Remove trailing slashes from the base directory\n",
    "                baseDirs.append(baseDir)\n",
    "                uncompressedDirPath = datadir + '/' + baseDir\n",
    "                if os.path.isdir(uncompressedDirPath): # if folder exists, do not try and uncompress and simply warn user\n",
    "                    print(\"The folder {} exists. Hence skipping uncompressing\".format(uncompressedDirPath))\n",
    "                    tar.close()\n",
    "                else:\n",
    "                    print(\"The folder does not exist. Proceeding with uncompressing\")\n",
    "                    tar.extractall(datadir)\n",
    "                    tar.close()   \n",
    "    return baseDirs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fee1e82",
   "metadata": {},
   "source": [
    "### Download all the OASIS-2 files and uncompress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef72c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download all tarfiles and uncompress them if needed\n",
    "for tarFile in tqdm(['OAS2_RAW_PART1.tar.gz', 'OAS2_RAW_PART2.tar.gz']):\n",
    "    # 1. Download tar.gz files (skip unless they already exist) and uncompress them\n",
    "    if not os.path.exists(\"{}/data/tar_gz_files/{}\".format(baseScratchPath,tarFile)):\n",
    "        url = \"https://download.nrg.wustl.edu/data/{}\".format(tarFile);\n",
    "        saveFilePath = \"{}/data/tar_gz_files/{}\".format(baseScratchPath,tarFile);\n",
    "        result = subprocess.run([\"wget\", \"-O\", saveFilePath, url]);\n",
    "    baseDirs = uncompressTar(\"{}/data\".format(baseScratchPath)) # Function returns base directories where uncompressed files will save to\n",
    "    # 2. Remove the tar.gz file to clean up space before next file is downloaded\n",
    "    if os.path.exists(\"{}/data/tar_gz_files/{}\".format(baseScratchPath,tarFile)):\n",
    "        subprocess.run([\"rm\", \"-rf\", \"{}/data/tar_gz_files/{}\".format(baseScratchPath,tarFile)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01229755",
   "metadata": {},
   "source": [
    "### Download the spreadsheets containing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d30c26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget https://www.oasis-brains.org/files/oasis_longitudinal_demographics.xlsx -O '../data/oasis_labelled_data/oasis_2_labelled_data.xlsx'\n",
    "\n",
    "# Download and load into Pandas datafram\n",
    "subprocess.run([\"wget\", \"-O\", '{}/milestone_II_project/data/oasis_labelled_data/oasis_2_labelled_data.xlsx'.format(baseHomePath), 'https://www.oasis-brains.org/files/oasis_longitudinal_demographics.xlsx']);\n",
    "oasis_2_datatable = pd.read_excel('{}/milestone_II_project/data/oasis_labelled_data/oasis_2_labelled_data.xlsx'.format(baseHomePath))\n",
    "\n",
    "# Display Pandas DataFrame as a table\n",
    "display(oasis_2_datatable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
